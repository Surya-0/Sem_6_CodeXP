{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T16:47:42.972961Z",
     "start_time": "2024-09-16T16:47:41.981725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.3076923076923077\n",
      "0.3\n",
      "0.18181818181818182\n",
      "0.4\n",
      "0.8235294117647058\n",
      "0.2857142857142857\n",
      "0.21052631578947367\n",
      "0.18181818181818182\n",
      "0.4\n",
      "0.375\n",
      "0.0\n",
      "0.13333333333333333\n",
      "0.1111111111111111\n",
      "0.16666666666666666\n",
      "0.23529411764705882\n",
      "N-Gram Corrected Word: I\n",
      "Soundex Corrected Word: Phonetic\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "from difflib import SequenceMatcher\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "# Inverted Index Construction\n",
    "def build_inverted_index(documents):\n",
    "    inverted_index = defaultdict(list)\n",
    "    for doc_id, text in enumerate(documents):\n",
    "        tokens = tokenize(text)\n",
    "        for token in tokens:\n",
    "            inverted_index[token].append(doc_id)\n",
    "    return inverted_index\n",
    "\n",
    "# Levenshtein Distance\n",
    "def levenshtein_distance(word1, word2):\n",
    "    print(SequenceMatcher(None, word1, word2).ratio())\n",
    "    return SequenceMatcher(None, word1, word2).ratio()\n",
    "\n",
    "# Spell Correction using N-Grams\n",
    "def generate_ngrams(word, n=3):\n",
    "    return list(ngrams(word, n))\n",
    "\n",
    "def spell_correction_ngram(word, vocabulary):\n",
    "    best_match = None\n",
    "    min_distance = float('inf')\n",
    "    for vocab_word in vocabulary:\n",
    "        distance = levenshtein_distance(word, vocab_word)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            best_match = vocab_word\n",
    "    return best_match\n",
    "\n",
    "# Soundex Algorithm for Phonetic Spell Correction\n",
    "def soundex(word):\n",
    "    \"\"\"Returns the soundex code for the word.\"\"\"\n",
    "    word = word.upper()\n",
    "    soundex_code = word[0]\n",
    "\n",
    "    soundex_mapping = {\n",
    "        \"BFPV\": \"1\", \"CGJKQSXZ\": \"2\", \"DT\": \"3\", \"L\": \"4\",\n",
    "        \"MN\": \"5\", \"R\": \"6\"\n",
    "    }\n",
    "\n",
    "    for char in word[1:]:\n",
    "        for key in soundex_mapping.keys():\n",
    "            if char in key:\n",
    "                code = soundex_mapping[key]\n",
    "                if code != soundex_code[-1]:  # Avoid duplicates\n",
    "                    soundex_code += code\n",
    "                break\n",
    "        if len(soundex_code) == 4:\n",
    "            break\n",
    "\n",
    "    soundex_code = (soundex_code + \"000\")[:4]  # Pad with zeros if necessary\n",
    "    return soundex_code\n",
    "\n",
    "def spell_correction_soundex(word, vocabulary):\n",
    "    \"\"\"Corrects spelling using Soundex codes.\"\"\"\n",
    "    word_soundex = soundex(word)\n",
    "    for vocab_word in vocabulary:\n",
    "        if soundex(vocab_word) == word_soundex:\n",
    "            return vocab_word\n",
    "    return word\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "documents = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Phonetic spell correction is interesting\",\n",
    "    \"Soundex is a useful algorithm for spelling\"\n",
    "]\n",
    "\n",
    "# Tokenize and build inverted index\n",
    "tokens = tokenize(documents[0])\n",
    "inverted_index = build_inverted_index(documents)\n",
    "\n",
    "# Test Spell Correction\n",
    "vocabulary = list(inverted_index.keys())\n",
    "word = \"phonetick\"\n",
    "corrected_ngram = spell_correction_ngram(word, vocabulary)\n",
    "corrected_soundex = spell_correction_soundex(word, vocabulary)\n",
    "\n",
    "print(f\"N-Gram Corrected Word: {corrected_ngram}\")\n",
    "print(f\"Soundex Corrected Word: {corrected_soundex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKENIZATION AND INVERTED INDEX FROM ABOVE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'programming', 'in', 'Python']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'I': [0],\n",
       "             'love': [0],\n",
       "             'programming': [0],\n",
       "             'in': [0],\n",
       "             'Python': [0],\n",
       "             'Phonetic': [1],\n",
       "             'spell': [1],\n",
       "             'correction': [1],\n",
       "             'is': [1, 2],\n",
       "             'interesting': [1],\n",
       "             'Soundex': [2],\n",
       "             'a': [2],\n",
       "             'useful': [2],\n",
       "             'algorithm': [2],\n",
       "             'for': [2],\n",
       "             'spelling': [2]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein Distance Example\n",
    "word1 = \"kitten\"\n",
    "word2 = \"sitting\"\n",
    "lev_distance = levenshtein_distance(word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance between 'kitten' and 'sitting': 3\n",
      "\n",
      "DP Table:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[1, 1, 2, 3, 4, 5, 6, 7]\n",
      "[2, 2, 1, 2, 3, 4, 5, 6]\n",
      "[3, 3, 2, 1, 2, 3, 4, 5]\n",
      "[4, 4, 3, 2, 1, 2, 3, 4]\n",
      "[5, 5, 4, 3, 2, 2, 3, 4]\n",
      "[6, 6, 5, 4, 3, 3, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Dynamic Programming approach for Levenshtein Distance\n",
    "def levenshtein_distance_dp(word1, word2):\n",
    "    # Create a 2D table to store the distances\n",
    "    m, n = len(word1), len(word2)\n",
    "    \n",
    "    # Initialize the table with 0 values\n",
    "    dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "\n",
    "    # Fill the first row and column with indices (base cases)\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    # Compute the distance using the recurrence relation\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if word1[i - 1] == word2[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            dp[i][j] = min(dp[i - 1][j] + 1,    # Deletion\n",
    "                           dp[i][j - 1] + 1,    # Insertion\n",
    "                           dp[i - 1][j - 1] + cost)  # Substitution\n",
    "\n",
    "    # The last cell contains the final Levenshtein distance\n",
    "    return dp[m][n], dp\n",
    "\n",
    "# Example usage:\n",
    "word1 = \"kitten\"\n",
    "word2 = \"sitting\"\n",
    "\n",
    "lev_distance, dp_table = levenshtein_distance_dp(word1, word2)\n",
    "\n",
    "# Output\n",
    "print(f\"Levenshtein Distance between '{word1}' and '{word2}': {lev_distance}\")\n",
    "\n",
    "# Optional: print the DP table for better understanding\n",
    "print(\"\\nDP Table:\")\n",
    "for row in dp_table:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text: hello\n",
      "Generating 3-grams:\n",
      "Step 1: ('h', 'e', 'l')\n",
      "Step 2: ('e', 'l', 'l')\n",
      "Step 3: ('l', 'l', 'o')\n",
      "\n",
      "3-grams for the word 'hello': [('h', 'e', 'l'), ('e', 'l', 'l'), ('l', 'l', 'o')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "# Function to generate n-grams and display the steps\n",
    "def generate_ngrams_visualization(text, n):\n",
    "    tokens = list(text)  # Tokenize the word into individual characters\n",
    "    print(f\"\\nOriginal Text: {text}\")\n",
    "    print(f\"Generating {n}-grams:\")\n",
    "    \n",
    "    # Generate the n-grams\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    # Display the steps\n",
    "    for i, ng in enumerate(ngrams_list):\n",
    "        print(f\"Step {i + 1}: {ng}\")\n",
    "\n",
    "    return ngrams_list\n",
    "\n",
    "# Example Usage\n",
    "word = \"hello\"\n",
    "n = 3\n",
    "ngrams_visualized = generate_ngrams_visualization(word, n)\n",
    "\n",
    "# Display the final result\n",
    "print(f\"\\n{n}-grams for the word '{word}': {ngrams_visualized}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOUNDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Keep the first letter -> S\n",
      "Convert 'M' to 5 -> S5\n",
      "Skip 'I' (not in mapping) -> S5\n",
      "Convert 'T' to 3 -> S53\n",
      "Skip 'H' (not in mapping) -> S53\n",
      "Final step: Pad with zeros -> S530\n",
      "\n",
      "Final Soundex Code for 'Smith': S530\n"
     ]
    }
   ],
   "source": [
    "# Soundex Algorithm with Adjacent Duplicate Removal and Zero Removal\n",
    "def soundex_step_by_step(word):\n",
    "    word = word.upper()  # Convert to uppercase\n",
    "    soundex_code = word[0]  # The first character remains as is\n",
    "\n",
    "    # Mapping of letters to Soundex digits\n",
    "    soundex_mapping = {\n",
    "        \"BFPV\": \"1\", \"CGJKQSXZ\": \"2\", \"DT\": \"3\", \"L\": \"4\",\n",
    "        \"MN\": \"5\", \"R\": \"6\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Step 1: Keep the first letter -> {soundex_code}\")\n",
    "    \n",
    "    # Generate the Soundex code\n",
    "    for char in word[1:]:\n",
    "        for key in soundex_mapping.keys():\n",
    "            if char in key:\n",
    "                code = soundex_mapping[key]\n",
    "                soundex_code += code\n",
    "                print(f\"Convert '{char}' to {code} -> {soundex_code}\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Skip '{char}' (not in mapping) -> {soundex_code}\")\n",
    "    \n",
    "    # Step 2: Remove adjacent duplicates\n",
    "    filtered_code = soundex_code[0]  # First character remains unchanged\n",
    "    for i in range(1, len(soundex_code)):\n",
    "        if soundex_code[i] != soundex_code[i - 1]:\n",
    "            filtered_code += soundex_code[i]\n",
    "\n",
    "    print(f\"Step 2: Remove adjacent duplicates -> {filtered_code}\")\n",
    "    \n",
    "    # Step 3: Remove any zeros\n",
    "    filtered_code = filtered_code.replace('0', '')\n",
    "    print(f\"Step 3: Remove '0's -> {filtered_code}\")\n",
    "\n",
    "    # Step 4: Pad with zeros if the code is shorter than 4 characters\n",
    "    final_code = (filtered_code + \"000\")[:4]\n",
    "    print(f\"Step 4: Pad with zeros -> {final_code}\")\n",
    "    \n",
    "    return final_code\n",
    "\n",
    "# Example Usage\n",
    "word = \"Smith\"\n",
    "soundex_code = soundex_step_by_step(word)\n",
    "\n",
    "print(f\"\\nFinal Soundex Code for '{word}': {soundex_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
