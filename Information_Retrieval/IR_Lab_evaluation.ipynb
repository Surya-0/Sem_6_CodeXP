{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b19c72cafa80f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7307ac6ef869466",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:25:39.380277Z",
     "start_time": "2024-09-17T04:25:39.368803Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ed4c0ddee6edc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Documents to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4e047f126880dfed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:48.940033Z",
     "start_time": "2024-09-17T04:23:48.863191Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc1 = \"Unthrifty loveliness why dost thou spend, Upon thy self thy beauty's legacy? Nature's bequest gives nothing but doth lend,And being frank she lends to those are free:Then beauteous niggard why dost thou abuse, The bounteous largess given thee to give? Profitless usurer why dost thou use So great a sum of sums yet canst not live? For having traffic with thy self alone, Thou of thy self thy sweet self dost deceive, Then howwhen nature calls thee to be gone,What acceptable audit canst thou leave?  Thy unused beauty must be tombed with thee,Which used lives th' executor to be.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a4fbfc46992da7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:48.978209Z",
     "start_time": "2024-09-17T04:23:48.869088Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Unthrifty loveliness why dost thou spend, Upon thy self thy beauty's legacy? Nature's bequest gives nothing but doth lend,And being frank she lends to those are free:Then beauteous niggard why dost thou abuse, The bounteous largess given thee to give? Profitless usurer why dost thou use So great a sum of sums yet canst not live? For having traffic with thy self alone, Thou of thy self thy sweet self dost deceive, Then howwhen nature calls thee to be gone,What acceptable audit canst thou leave?  Thy unused beauty must be tombed with thee,Which used lives th' executor to be.\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b2d98edb61f2b019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:48.983252Z",
     "start_time": "2024-09-17T04:23:48.871239Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2 = \"Those hours that with gentle work did frame The lovely gaze where every eye doth dwell Will play the tyrants to the very same,And that unfair which fairly doth excel: For never-resting time leads summer on To hideous winter and confounds him there, Sap checked with frost and lusty leaves quite gone,Beauty o'er-snowed and bareness every where: Then were not summer's distillation left A liquid prisoner pent in walls of glass, Beauty's effect with beauty were bereft, Nor it nor no remembrance what it was. But flowers distilled though they with winter meet,Leese but their show, their substance still lives sweet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5aa67f1429e7d21a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:48.983368Z",
     "start_time": "2024-09-17T04:23:48.872817Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Those hours that with gentle work did frame The lovely gaze where every eye doth dwell Will play the tyrants to the very same,And that unfair which fairly doth excel: For never-resting time leads summer on To hideous winter and confounds him there, Sap checked with frost and lusty leaves quite gone,Beauty o'er-snowed and bareness every where: Then were not summer's distillation left A liquid prisoner pent in walls of glass, Beauty's effect with beauty were bereft, Nor it nor no remembrance what it was. But flowers distilled though they with winter meet,Leese but their show, their substance still lives sweet\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f8a9864a9ccb78e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:48.999830Z",
     "start_time": "2024-09-17T04:23:48.877087Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc3 = \"Then let not winter's ragged hand deface, In thee thy summer ere thou be distilled:Make sweet some vial; treasure thou some place, With beauty's treasure ere it be self-killed: That use is not forbidden usury,Which happies those that pay the willing loan; That's for thy self to breed another thee, Or ten times happier be it ten for one, Ten times thy self were happier than thou art, If ten of thine ten times refigured thee: Then what could death do if thou shouldst depart, Leaving thee living in posterity? Be not self-willed for thou art much too fair, To be death's conquest and make worms thine heir.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "59fd669806d6620b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:48.999964Z",
     "start_time": "2024-09-17T04:23:48.879840Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Then let not winter's ragged hand deface, In thee thy summer ere thou be distilled:Make sweet some vial; treasure thou some place, With beauty's treasure ere it be self-killed: That use is not forbidden usury,Which happies those that pay the willing loan; That's for thy self to breed another thee, Or ten times happier be it ten for one, Ten times thy self were happier than thou art, If ten of thine ten times refigured thee: Then what could death do if thou shouldst depart, Leaving thee living in posterity? Be not self-willed for thou art much too fair, To be death's conquest and make worms thine heir.\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca9e2eec8f9111",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a947984fecfad7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Steps : \n",
    "1. First form the collections for removing stopwords and punctuations from your documents\n",
    "2. Tokenize all the documents using the word_tokenize function from nltk\n",
    "3. Remove the stopwords and punctuations from your tokens and create token_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e31aecab5ca1ef2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.020141Z",
     "start_time": "2024-09-17T04:23:48.882574Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punctuations = set(string.punctuation)\n",
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "52762882c580e28d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.021756Z",
     "start_time": "2024-09-17T04:23:48.888745Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_collection = set(stopwords.words('English'))\n",
    "stopwords_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "31833ff8243c05c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.022594Z",
     "start_time": "2024-09-17T04:23:48.895003Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_doc1 = word_tokenize(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ff50729a875d86a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.022711Z",
     "start_time": "2024-09-17T04:23:48.897823Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unthrifty',\n",
       " 'loveliness',\n",
       " 'why',\n",
       " 'dost',\n",
       " 'thou',\n",
       " 'spend',\n",
       " ',',\n",
       " 'Upon',\n",
       " 'thy',\n",
       " 'self',\n",
       " 'thy',\n",
       " 'beauty',\n",
       " \"'s\",\n",
       " 'legacy',\n",
       " '?',\n",
       " 'Nature',\n",
       " \"'s\",\n",
       " 'bequest',\n",
       " 'gives',\n",
       " 'nothing',\n",
       " 'but',\n",
       " 'doth',\n",
       " 'lend',\n",
       " ',',\n",
       " 'And',\n",
       " 'being',\n",
       " 'frank',\n",
       " 'she',\n",
       " 'lends',\n",
       " 'to',\n",
       " 'those',\n",
       " 'are',\n",
       " 'free',\n",
       " ':',\n",
       " 'Then',\n",
       " 'beauteous',\n",
       " 'niggard',\n",
       " 'why',\n",
       " 'dost',\n",
       " 'thou',\n",
       " 'abuse',\n",
       " ',',\n",
       " 'The',\n",
       " 'bounteous',\n",
       " 'largess',\n",
       " 'given',\n",
       " 'thee',\n",
       " 'to',\n",
       " 'give',\n",
       " '?',\n",
       " 'Profitless',\n",
       " 'usurer',\n",
       " 'why',\n",
       " 'dost',\n",
       " 'thou',\n",
       " 'use',\n",
       " 'So',\n",
       " 'great',\n",
       " 'a',\n",
       " 'sum',\n",
       " 'of',\n",
       " 'sums',\n",
       " 'yet',\n",
       " 'canst',\n",
       " 'not',\n",
       " 'live',\n",
       " '?',\n",
       " 'For',\n",
       " 'having',\n",
       " 'traffic',\n",
       " 'with',\n",
       " 'thy',\n",
       " 'self',\n",
       " 'alone',\n",
       " ',',\n",
       " 'Thou',\n",
       " 'of',\n",
       " 'thy',\n",
       " 'self',\n",
       " 'thy',\n",
       " 'sweet',\n",
       " 'self',\n",
       " 'dost',\n",
       " 'deceive',\n",
       " ',',\n",
       " 'Then',\n",
       " 'howwhen',\n",
       " 'nature',\n",
       " 'calls',\n",
       " 'thee',\n",
       " 'to',\n",
       " 'be',\n",
       " 'gone',\n",
       " ',',\n",
       " 'What',\n",
       " 'acceptable',\n",
       " 'audit',\n",
       " 'canst',\n",
       " 'thou',\n",
       " 'leave',\n",
       " '?',\n",
       " 'Thy',\n",
       " 'unused',\n",
       " 'beauty',\n",
       " 'must',\n",
       " 'be',\n",
       " 'tombed',\n",
       " 'with',\n",
       " 'thee',\n",
       " ',',\n",
       " 'Which',\n",
       " 'used',\n",
       " 'lives',\n",
       " 'th',\n",
       " \"'\",\n",
       " 'executor',\n",
       " 'to',\n",
       " 'be',\n",
       " '.']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30b5c3f27f9d409d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023039Z",
     "start_time": "2024-09-17T04:23:48.900428Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_doc2 = word_tokenize(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dbc7312acd656ae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023149Z",
     "start_time": "2024-09-17T04:23:48.902896Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Those',\n",
       " 'hours',\n",
       " 'that',\n",
       " 'with',\n",
       " 'gentle',\n",
       " 'work',\n",
       " 'did',\n",
       " 'frame',\n",
       " 'The',\n",
       " 'lovely',\n",
       " 'gaze',\n",
       " 'where',\n",
       " 'every',\n",
       " 'eye',\n",
       " 'doth',\n",
       " 'dwell',\n",
       " 'Will',\n",
       " 'play',\n",
       " 'the',\n",
       " 'tyrants',\n",
       " 'to',\n",
       " 'the',\n",
       " 'very',\n",
       " 'same',\n",
       " ',',\n",
       " 'And',\n",
       " 'that',\n",
       " 'unfair',\n",
       " 'which',\n",
       " 'fairly',\n",
       " 'doth',\n",
       " 'excel',\n",
       " ':',\n",
       " 'For',\n",
       " 'never-resting',\n",
       " 'time',\n",
       " 'leads',\n",
       " 'summer',\n",
       " 'on',\n",
       " 'To',\n",
       " 'hideous',\n",
       " 'winter',\n",
       " 'and',\n",
       " 'confounds',\n",
       " 'him',\n",
       " 'there',\n",
       " ',',\n",
       " 'Sap',\n",
       " 'checked',\n",
       " 'with',\n",
       " 'frost',\n",
       " 'and',\n",
       " 'lusty',\n",
       " 'leaves',\n",
       " 'quite',\n",
       " 'gone',\n",
       " ',',\n",
       " 'Beauty',\n",
       " \"o'er-snowed\",\n",
       " 'and',\n",
       " 'bareness',\n",
       " 'every',\n",
       " 'where',\n",
       " ':',\n",
       " 'Then',\n",
       " 'were',\n",
       " 'not',\n",
       " 'summer',\n",
       " \"'s\",\n",
       " 'distillation',\n",
       " 'left',\n",
       " 'A',\n",
       " 'liquid',\n",
       " 'prisoner',\n",
       " 'pent',\n",
       " 'in',\n",
       " 'walls',\n",
       " 'of',\n",
       " 'glass',\n",
       " ',',\n",
       " 'Beauty',\n",
       " \"'s\",\n",
       " 'effect',\n",
       " 'with',\n",
       " 'beauty',\n",
       " 'were',\n",
       " 'bereft',\n",
       " ',',\n",
       " 'Nor',\n",
       " 'it',\n",
       " 'nor',\n",
       " 'no',\n",
       " 'remembrance',\n",
       " 'what',\n",
       " 'it',\n",
       " 'was',\n",
       " '.',\n",
       " 'But',\n",
       " 'flowers',\n",
       " 'distilled',\n",
       " 'though',\n",
       " 'they',\n",
       " 'with',\n",
       " 'winter',\n",
       " 'meet',\n",
       " ',',\n",
       " 'Leese',\n",
       " 'but',\n",
       " 'their',\n",
       " 'show',\n",
       " ',',\n",
       " 'their',\n",
       " 'substance',\n",
       " 'still',\n",
       " 'lives',\n",
       " 'sweet']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "be273f85a7d29ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023179Z",
     "start_time": "2024-09-17T04:23:48.907636Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_doc3 = word_tokenize(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6416286810867d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023274Z",
     "start_time": "2024-09-17T04:23:48.910001Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Then',\n",
       " 'let',\n",
       " 'not',\n",
       " 'winter',\n",
       " \"'s\",\n",
       " 'ragged',\n",
       " 'hand',\n",
       " 'deface',\n",
       " ',',\n",
       " 'In',\n",
       " 'thee',\n",
       " 'thy',\n",
       " 'summer',\n",
       " 'ere',\n",
       " 'thou',\n",
       " 'be',\n",
       " 'distilled',\n",
       " ':',\n",
       " 'Make',\n",
       " 'sweet',\n",
       " 'some',\n",
       " 'vial',\n",
       " ';',\n",
       " 'treasure',\n",
       " 'thou',\n",
       " 'some',\n",
       " 'place',\n",
       " ',',\n",
       " 'With',\n",
       " 'beauty',\n",
       " \"'s\",\n",
       " 'treasure',\n",
       " 'ere',\n",
       " 'it',\n",
       " 'be',\n",
       " 'self-killed',\n",
       " ':',\n",
       " 'That',\n",
       " 'use',\n",
       " 'is',\n",
       " 'not',\n",
       " 'forbidden',\n",
       " 'usury',\n",
       " ',',\n",
       " 'Which',\n",
       " 'happies',\n",
       " 'those',\n",
       " 'that',\n",
       " 'pay',\n",
       " 'the',\n",
       " 'willing',\n",
       " 'loan',\n",
       " ';',\n",
       " 'That',\n",
       " \"'s\",\n",
       " 'for',\n",
       " 'thy',\n",
       " 'self',\n",
       " 'to',\n",
       " 'breed',\n",
       " 'another',\n",
       " 'thee',\n",
       " ',',\n",
       " 'Or',\n",
       " 'ten',\n",
       " 'times',\n",
       " 'happier',\n",
       " 'be',\n",
       " 'it',\n",
       " 'ten',\n",
       " 'for',\n",
       " 'one',\n",
       " ',',\n",
       " 'Ten',\n",
       " 'times',\n",
       " 'thy',\n",
       " 'self',\n",
       " 'were',\n",
       " 'happier',\n",
       " 'than',\n",
       " 'thou',\n",
       " 'art',\n",
       " ',',\n",
       " 'If',\n",
       " 'ten',\n",
       " 'of',\n",
       " 'thine',\n",
       " 'ten',\n",
       " 'times',\n",
       " 'refigured',\n",
       " 'thee',\n",
       " ':',\n",
       " 'Then',\n",
       " 'what',\n",
       " 'could',\n",
       " 'death',\n",
       " 'do',\n",
       " 'if',\n",
       " 'thou',\n",
       " 'shouldst',\n",
       " 'depart',\n",
       " ',',\n",
       " 'Leaving',\n",
       " 'thee',\n",
       " 'living',\n",
       " 'in',\n",
       " 'posterity',\n",
       " '?',\n",
       " 'Be',\n",
       " 'not',\n",
       " 'self-willed',\n",
       " 'for',\n",
       " 'thou',\n",
       " 'art',\n",
       " 'much',\n",
       " 'too',\n",
       " 'fair',\n",
       " ',',\n",
       " 'To',\n",
       " 'be',\n",
       " 'death',\n",
       " \"'s\",\n",
       " 'conquest',\n",
       " 'and',\n",
       " 'make',\n",
       " 'worms',\n",
       " 'thine',\n",
       " 'heir',\n",
       " '.']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "19fb04e7f1eb96cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023302Z",
     "start_time": "2024-09-17T04:23:48.912515Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def token_doc_stram_creator(token_doc):\n",
    "    token_doc_stream = []\n",
    "    for word in token_doc:\n",
    "        if word.lower() not in stopwords_collection and word.lower() not in punctuations:\n",
    "            token_doc_stream.append(word.lower())\n",
    "    return token_doc_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2f560c4dfc1b3b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023330Z",
     "start_time": "2024-09-17T04:23:48.915073Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_doc1_stream = token_doc_stram_creator(token_doc1)\n",
    "token_doc2_stream = token_doc_stram_creator(token_doc2)\n",
    "token_doc3_stream = token_doc_stram_creator(token_doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c98c76f1215219a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023409Z",
     "start_time": "2024-09-17T04:23:48.916701Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119   75\n"
     ]
    }
   ],
   "source": [
    "print(len(token_doc1), \" \",len(token_doc1_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dc921f5b106ebc50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023462Z",
     "start_time": "2024-09-17T04:23:48.918779Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116   60\n"
     ]
    }
   ],
   "source": [
    "print(len(token_doc2),\" \",len(token_doc2_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "300576b2c422b879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023512Z",
     "start_time": "2024-09-17T04:23:48.920618Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129   75\n"
     ]
    }
   ],
   "source": [
    "print(len(token_doc3),\" \",len(token_doc3_stream))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d4fd0ea009974",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Inverted Index construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff0bfa5fc8da5d4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Steps : \n",
    "1. Take each of the token streams and parse them\n",
    "2. Have a dictionary which stores the token i.e., the word as the key and the documents in which the tokens are present as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9e226db67baad48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023538Z",
     "start_time": "2024-09-17T04:23:48.922606Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inverted_index = defaultdict(list)\n",
    "def construct_inverted_index(token_stream,doc_number):\n",
    "    for token in token_stream:\n",
    "        if doc_number not in inverted_index[token]: \n",
    "            inverted_index[token].append(doc_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e470e01c2bb2a4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023562Z",
     "start_time": "2024-09-17T04:23:48.924327Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "construct_inverted_index(token_doc1_stream,1)\n",
    "construct_inverted_index(token_doc2_stream,2)\n",
    "construct_inverted_index(token_doc3_stream,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "926e125be8241b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023690Z",
     "start_time": "2024-09-17T04:23:48.928430Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'unthrifty': [1],\n",
       "             'loveliness': [1],\n",
       "             'dost': [1],\n",
       "             'thou': [1, 3],\n",
       "             'spend': [1],\n",
       "             'upon': [1],\n",
       "             'thy': [1, 3],\n",
       "             'self': [1, 3],\n",
       "             'beauty': [1, 2, 3],\n",
       "             \"'s\": [1, 2, 3],\n",
       "             'legacy': [1],\n",
       "             'nature': [1],\n",
       "             'bequest': [1],\n",
       "             'gives': [1],\n",
       "             'nothing': [1],\n",
       "             'doth': [1, 2],\n",
       "             'lend': [1],\n",
       "             'frank': [1],\n",
       "             'lends': [1],\n",
       "             'free': [1],\n",
       "             'beauteous': [1],\n",
       "             'niggard': [1],\n",
       "             'abuse': [1],\n",
       "             'bounteous': [1],\n",
       "             'largess': [1],\n",
       "             'given': [1],\n",
       "             'thee': [1, 3],\n",
       "             'give': [1],\n",
       "             'profitless': [1],\n",
       "             'usurer': [1],\n",
       "             'use': [1, 3],\n",
       "             'great': [1],\n",
       "             'sum': [1],\n",
       "             'sums': [1],\n",
       "             'yet': [1],\n",
       "             'canst': [1],\n",
       "             'live': [1],\n",
       "             'traffic': [1],\n",
       "             'alone': [1],\n",
       "             'sweet': [1, 2, 3],\n",
       "             'deceive': [1],\n",
       "             'howwhen': [1],\n",
       "             'calls': [1],\n",
       "             'gone': [1, 2],\n",
       "             'acceptable': [1],\n",
       "             'audit': [1],\n",
       "             'leave': [1],\n",
       "             'unused': [1],\n",
       "             'must': [1],\n",
       "             'tombed': [1],\n",
       "             'used': [1],\n",
       "             'lives': [1, 2],\n",
       "             'th': [1],\n",
       "             'executor': [1],\n",
       "             'hours': [2],\n",
       "             'gentle': [2],\n",
       "             'work': [2],\n",
       "             'frame': [2],\n",
       "             'lovely': [2],\n",
       "             'gaze': [2],\n",
       "             'every': [2],\n",
       "             'eye': [2],\n",
       "             'dwell': [2],\n",
       "             'play': [2],\n",
       "             'tyrants': [2],\n",
       "             'unfair': [2],\n",
       "             'fairly': [2],\n",
       "             'excel': [2],\n",
       "             'never-resting': [2],\n",
       "             'time': [2],\n",
       "             'leads': [2],\n",
       "             'summer': [2, 3],\n",
       "             'hideous': [2],\n",
       "             'winter': [2, 3],\n",
       "             'confounds': [2],\n",
       "             'sap': [2],\n",
       "             'checked': [2],\n",
       "             'frost': [2],\n",
       "             'lusty': [2],\n",
       "             'leaves': [2],\n",
       "             'quite': [2],\n",
       "             \"o'er-snowed\": [2],\n",
       "             'bareness': [2],\n",
       "             'distillation': [2],\n",
       "             'left': [2],\n",
       "             'liquid': [2],\n",
       "             'prisoner': [2],\n",
       "             'pent': [2],\n",
       "             'walls': [2],\n",
       "             'glass': [2],\n",
       "             'effect': [2],\n",
       "             'bereft': [2],\n",
       "             'remembrance': [2],\n",
       "             'flowers': [2],\n",
       "             'distilled': [2, 3],\n",
       "             'though': [2],\n",
       "             'meet': [2],\n",
       "             'leese': [2],\n",
       "             'show': [2],\n",
       "             'substance': [2],\n",
       "             'still': [2],\n",
       "             'let': [3],\n",
       "             'ragged': [3],\n",
       "             'hand': [3],\n",
       "             'deface': [3],\n",
       "             'ere': [3],\n",
       "             'make': [3],\n",
       "             'vial': [3],\n",
       "             'treasure': [3],\n",
       "             'place': [3],\n",
       "             'self-killed': [3],\n",
       "             'forbidden': [3],\n",
       "             'usury': [3],\n",
       "             'happies': [3],\n",
       "             'pay': [3],\n",
       "             'willing': [3],\n",
       "             'loan': [3],\n",
       "             'breed': [3],\n",
       "             'another': [3],\n",
       "             'ten': [3],\n",
       "             'times': [3],\n",
       "             'happier': [3],\n",
       "             'one': [3],\n",
       "             'art': [3],\n",
       "             'thine': [3],\n",
       "             'refigured': [3],\n",
       "             'could': [3],\n",
       "             'death': [3],\n",
       "             'shouldst': [3],\n",
       "             'depart': [3],\n",
       "             'leaving': [3],\n",
       "             'living': [3],\n",
       "             'posterity': [3],\n",
       "             'self-willed': [3],\n",
       "             'much': [3],\n",
       "             'fair': [3],\n",
       "             'conquest': [3],\n",
       "             'worms': [3],\n",
       "             'heir': [3]})"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5637c313a284c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Result for query thee AND self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b372f8abdb1ca78",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Steps : \n",
    "1. Retrieve the postings list from the inverted index for each word\n",
    "2. Take the intersections of both the postings list \n",
    "3. The resultant intersected list is your answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d020f64434e22da1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023742Z",
     "start_time": "2024-09-17T04:23:48.930707Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 3}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thee_occ = set(inverted_index['thee'])\n",
    "thee_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "77a3738ac586c74f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023791Z",
     "start_time": "2024-09-17T04:23:48.933237Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 3}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_occ = set(inverted_index['self'])\n",
    "self_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e2ee67af92be9e7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023846Z",
     "start_time": "2024-09-17T04:23:48.935599Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 3}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection = (thee_occ & self_occ)\n",
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d91032b54689d6da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.023896Z",
     "start_time": "2024-09-17T04:23:48.937571Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae32de9bfe2245",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Spell correction using Levenshtein distance with dynamic programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814db94a75ec8a6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Steps :\n",
    "1. Take the entire vocabulary from the inverted index \n",
    "2. Create a function for Levenshtein distance\n",
    "3. Calculate the distance between each word in the vocabulary and the query\n",
    "4. Whichever word yields the min distance that is your best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "69eedae0f0b88f78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.024375Z",
     "start_time": "2024-09-17T04:23:48.941232Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def levenshtein_distance(word1, word2):\n",
    "    m, n = len(word1),len(word2)\n",
    "    dp = [[0 for i in range(n+1)] for j in range(m+1)]\n",
    "    \n",
    "    for i in range(m+1):\n",
    "        dp[i][0] = i\n",
    "    \n",
    "    for j in range(n+1):\n",
    "        dp[0][j] = j\n",
    "        \n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            if word1[i-1] == word2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            \n",
    "            else:\n",
    "                dp[i][j] = min(dp[i-1][j-1] + 1,dp[i-1][j] + 1,dp[i][j-1] + 1)\n",
    "            \n",
    "    return dp[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "46f52a9b557f9fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.024406Z",
     "start_time": "2024-09-17T04:23:48.943023Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = 'wire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4f67a5bd5c76cb91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.024467Z",
     "start_time": "2024-09-17T04:23:48.944653Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = list(inverted_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "58176c09797e193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.024530Z",
     "start_time": "2024-09-17T04:23:48.946611Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unthrifty', 'loveliness', 'dost', 'thou', 'spend', 'upon', 'thy', 'self', 'beauty', \"'s\", 'legacy', 'nature', 'bequest', 'gives', 'nothing', 'doth', 'lend', 'frank', 'lends', 'free', 'beauteous', 'niggard', 'abuse', 'bounteous', 'largess', 'given', 'thee', 'give', 'profitless', 'usurer', 'use', 'great', 'sum', 'sums', 'yet', 'canst', 'live', 'traffic', 'alone', 'sweet', 'deceive', 'howwhen', 'calls', 'gone', 'acceptable', 'audit', 'leave', 'unused', 'must', 'tombed', 'used', 'lives', 'th', 'executor', 'hours', 'gentle', 'work', 'frame', 'lovely', 'gaze', 'every', 'eye', 'dwell', 'play', 'tyrants', 'unfair', 'fairly', 'excel', 'never-resting', 'time', 'leads', 'summer', 'hideous', 'winter', 'confounds', 'sap', 'checked', 'frost', 'lusty', 'leaves', 'quite', \"o'er-snowed\", 'bareness', 'distillation', 'left', 'liquid', 'prisoner', 'pent', 'walls', 'glass', 'effect', 'bereft', 'remembrance', 'flowers', 'distilled', 'though', 'meet', 'leese', 'show', 'substance', 'still', 'let', 'ragged', 'hand', 'deface', 'ere', 'make', 'vial', 'treasure', 'place', 'self-killed', 'forbidden', 'usury', 'happies', 'pay', 'willing', 'loan', 'breed', 'another', 'ten', 'times', 'happier', 'one', 'art', 'thine', 'refigured', 'could', 'death', 'shouldst', 'depart', 'leaving', 'living', 'posterity', 'self-willed', 'much', 'fair', 'conquest', 'worms', 'heir']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9bf78822e9ff2970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.024804Z",
     "start_time": "2024-09-17T04:23:48.948715Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(query in vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "11ad5c33c826dcca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.024866Z",
     "start_time": "2024-09-17T04:23:48.952023Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give\n"
     ]
    }
   ],
   "source": [
    "best_match = None\n",
    "min_dist = float('inf')\n",
    "for vocab in vocabulary:\n",
    "    new_dist = levenshtein_distance(vocab,query)\n",
    "    if new_dist < min_dist:\n",
    "        min_dist = new_dist\n",
    "        best_match = vocab\n",
    "\n",
    "print(best_match)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f851a77ac07afceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T04:23:49.024899Z",
     "start_time": "2024-09-17T04:23:48.953525Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
